{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Line_reg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(r'linreg.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+-----+-----+------+\n",
      "|var_1|var_2|var_3|var_4|var_5|output|\n",
      "+-----+-----+-----+-----+-----+------+\n",
      "|  734|  688|   81|0.328|0.259| 0.418|\n",
      "|  700|  600|   94| 0.32|0.247| 0.389|\n",
      "|  712|  705|   93|0.311|0.247| 0.417|\n",
      "|  734|  806|   69|0.315| 0.26| 0.415|\n",
      "|  613|  759|   61|0.302| 0.24| 0.378|\n",
      "|  748|  676|   85|0.318|0.255| 0.422|\n",
      "|  669|  588|   97|0.315|0.251| 0.411|\n",
      "|  667|  845|   68|0.324|0.251| 0.381|\n",
      "|  758|  890|   64| 0.33|0.274| 0.436|\n",
      "|  726|  670|   88|0.335|0.268| 0.422|\n",
      "|  583|  794|   55|0.302|0.236| 0.371|\n",
      "|  676|  746|   72|0.317|0.265|   0.4|\n",
      "|  767|  699|   89|0.332|0.274| 0.433|\n",
      "|  637|  597|   86|0.317|0.252| 0.374|\n",
      "|  609|  724|   69|0.308|0.244| 0.382|\n",
      "|  776|  733|   83|0.325|0.259| 0.437|\n",
      "|  701|  832|   66|0.325| 0.26|  0.39|\n",
      "|  650|  709|   74|0.316|0.249| 0.386|\n",
      "|  804|  668|   95|0.337|0.265| 0.453|\n",
      "|  713|  614|   94| 0.31|0.238| 0.404|\n",
      "+-----+-----+-----+-----+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1232"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- var_1: integer (nullable = true)\n",
      " |-- var_2: integer (nullable = true)\n",
      " |-- var_3: integer (nullable = true)\n",
      " |-- var_4: double (nullable = true)\n",
      " |-- var_5: double (nullable = true)\n",
      " |-- output: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|summary|            var_1|            var_2|             var_3|               var_4|               var_5|             output|\n",
      "+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|  count|             1232|             1232|              1232|                1232|                1232|               1232|\n",
      "|   mean|715.0819805194806|715.0819805194806| 80.90422077922078|  0.3263311688311693| 0.25927272727272715|0.39734172077922014|\n",
      "| stddev| 91.5342940441652|93.07993263118064|11.458139049993724|0.015012772334166148|0.012907228928000298|0.03326689862173776|\n",
      "|    min|              463|              472|                40|               0.277|               0.214|              0.301|\n",
      "|    max|             1009|             1103|               116|               0.373|               0.294|              0.491|\n",
      "+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correlations of all variables wrt output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|corr(var_1, output)|\n",
      "+-------------------+\n",
      "| 0.9187399607627283|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|corr(var_2, output)|\n",
      "+-------------------+\n",
      "|0.43652698913681093|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|corr(var_3, output)|\n",
      "+-------------------+\n",
      "| 0.4014958408311139|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|corr(var_4, output)|\n",
      "+-------------------+\n",
      "| 0.7909100204842113|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|corr(var_5, output)|\n",
      "+-------------------+\n",
      "| 0.7904806260381185|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns[:-1]:\n",
    "    df.select(corr(df[col], df['output'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'output']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_asmblr = VectorAssembler(inputCols=df.columns[:-1], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = vec_asmblr.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('features','output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- output: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(922, 310)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count(),test_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression(labelCol='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = lin_reg.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0003, 0.0001, 0.0003, -0.7147, 0.481])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19502440626807166"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = lin_reg.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8813641574262024"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013318356462116516"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
